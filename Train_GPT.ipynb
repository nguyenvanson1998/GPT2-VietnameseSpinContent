{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71a794b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in /home/thienchuaheadshot_gmail_com/.local/lib/python3.8/site-packages (1.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2faaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e05d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"XRT_TPU_CONFIG\"] = \"localservice;0;localhost:51011\"\n",
    "import datasets\n",
    "from transformers import EncoderDecoderModel\n",
    "from datasets import load_dataset\n",
    "from transformers import BertConfig, EncoderDecoderConfig,EncoderDecoderModel\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict\n",
    "import joblib\n",
    "from transformers import PreTrainedTokenizer\n",
    "from tqdm import tqdm\n",
    "os.environ['HF_DATASETS_CACHE'] = \"~/temp/cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3a0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff45d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n",
    "                         AdamW, get_linear_schedule_with_warmup, \\\n",
    "                         TrainingArguments, BeamScorer, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e83a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#######load tokenizer\n",
    "print(\"Load Data\")\n",
    "\n",
    "full_data = datasets.load_from_disk(\"/home/thienchuaheadshot_gmail_com/spin_content/data_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fd732c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'Giày búp bê mũi tròn',\n",
       " 'name': 'GIẦY BÚP BÊ NỮ ALDO BRAYLYNN',\n",
       " 'brand': 'ALDO',\n",
       " 'text': 'thương hiệu thời trang aldo là hãng thời trang canada chuyên mang đến những thiết kế sang trọng và tinh tế về phụ kiện giầy dép và túi xách. aldo được phân phối độc quyền tại việt nam bởi công ty cổ phần nhà thái từ năm 2009. túi và phụ kiện aldo không có hộp và túi vải. cần hỗ trợ tư vấn, vui lòng inbox nhân viên cskh của aldo.',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a00476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load Tokenizer\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"NlpHUST/gpt2-vietnamese\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"NlpHUST/gpt2-vietnamese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe814ad",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0672758",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNFREEZE_LAST_N = 6\n",
    "\n",
    "\n",
    "# MODEL = \"NlpHUST/gpt2-vietnamese\"\n",
    "MODEL = \"imthanhlv/gpt2news\"\n",
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "TRAIN_SIZE      = 0.8\n",
    "TRAIN_BATCHSIZE = 32\n",
    "BATCH_UPDATE    = 64\n",
    "\n",
    "\n",
    "MAXLEN          = 768    #{768, 1024, 1280, 1600}\n",
    "EPOCHS          = 4\n",
    "LR              = 5e-4\n",
    "EPS             = 1e-8\n",
    "WARMUP_STEPS    = 1000\n",
    "\n",
    "SEED            = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2547981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9650b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenier(special_tokens=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n",
    "\n",
    "    if special_tokens:\n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "        print(\"Special tokens added\")\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(tokenizer, special_tokens=None, load_model_path=None):\n",
    "\n",
    "    #GPT2LMHeadModel\n",
    "    if special_tokens:\n",
    "        config = AutoConfig.from_pretrained(MODEL, \n",
    "                                            bos_token_id=tokenizer.bos_token_id,\n",
    "                                            eos_token_id=tokenizer.eos_token_id,\n",
    "                                            sep_token_id=tokenizer.sep_token_id,\n",
    "                                            pad_token_id=tokenizer.pad_token_id,\n",
    "                                            output_hidden_states=False)\n",
    "    else: \n",
    "        config = AutoConfig.from_pretrained(MODEL,                                     \n",
    "                                            pad_token_id=tokenizer.eos_token_id,\n",
    "                                            output_hidden_states=False)    \n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
    "\n",
    "    if special_tokens:\n",
    "        #Special tokens added, model needs to be resized accordingly\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if load_model_path:\n",
    "        #model = AutoModel.from_pretrained(load_model_path)\n",
    "        model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c614146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens added\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
    "model = get_model(tokenizer, \n",
    "                  special_tokens=SPECIAL_TOKENS,\n",
    "                #   load_model_path='pytorch_model.bin'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5d101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"imthanhlv/gpt2news\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.0,\n",
       "  \"bos_token_id\": 50258,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": 50259,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"pad_token_id\": 50261,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"sep_token_id\": 50262,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 150\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.22.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50263\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a903e",
   "metadata": {},
   "source": [
    "# Data and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71806180",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [{\"text\":\"Đây là sản phẩm giày cao gót đi vừa êm vừa sướng, đi rất là tôn giáng đó!\", \"name\": 'GIẦY BÚP BÊ NỮ ALDO BRAYLYNN'},\n",
    "     {\"text\":\"Giày này không bán em ơi!\", \"name\": 'GIẦY BÚP BÊ NỮ NVIDIA'}]\n",
    "names = [x['name'] for x in batch]\n",
    "texts = [x['text'] for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b61b2535",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([ SPECIAL_TOKENS['bos_token'] + name + SPECIAL_TOKENS['sep_token'] + text + SPECIAL_TOKENS['eos_token'] for name,text in zip(names,texts)], padding = \"max_length\", truncation=True, max_length=MAXLEN,return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d0a88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50258, 14063,  7905, ..., 50261, 50261, 50261],\n",
       "       [50258, 14063,  7905, ..., 50261, 50261, 50261]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219ef4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):                                                               \n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]  \n",
    "    names = batch['name']\n",
    "    texts = batch['text']\n",
    "    brands = batch['brand']\n",
    "    categories = batch['category']\n",
    "    inputs = tokenizer([ SPECIAL_TOKENS['bos_token'] + category+  SPECIAL_TOKENS['sep_token'] + brand+  SPECIAL_TOKENS['sep_token'] +text + SPECIAL_TOKENS['sep_token'] + name + SPECIAL_TOKENS['eos_token'] for category, brand,text, name in zip(categories, brands, texts,names)], padding = \"max_length\", truncation=True, max_length=MAXLEN,return_tensors=\"np\")\n",
    "    batch[\"labels\"] = inputs.input_ids \n",
    "    batch[\"input_ids\"] = inputs.input_ids                                                               \n",
    "    batch[\"attention_mask\"] = inputs.attention_mask                                                                                                                                           \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a28c5625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-d6a13d425753ce20.arrow\n"
     ]
    }
   ],
   "source": [
    "full_data = full_data.filter(lambda x: len(x[\"text\"]) > 8 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bbf6257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-a7e3144ae27520be.arrow\n"
     ]
    }
   ],
   "source": [
    "def fill_none_data(text):\n",
    "    if text['brand'] is None:\n",
    "        text['brand'] = ''\n",
    "    return text\n",
    "\n",
    "full_data1 = full_data.map(\n",
    "    fill_none_data,\n",
    "    batched = False,\n",
    "    num_proc = 1,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "350d7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "for str_i in full_data1:\n",
    "    if str_i['brand'] is None:\n",
    "        \n",
    "        print(str_i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a876259a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-15846c6a1cc5cc97.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-7599577a4acb1a8f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-6856399ae46f5aa3.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-316b86951a47c059.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-5d769e44deb2b2c5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-bd4a20661bf9e1fc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-d6dde7ca3337ad31.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-a97409e9e48db787.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-e884a14af3799dfc.arrow\n",
      "Loading cached processed dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-b11bc05c850e9458.arrow\n"
     ]
    }
   ],
   "source": [
    "train_data = full_data1.map(\n",
    "    process_data_to_model_inputs, \n",
    "    batched=True, \n",
    "#     batch_size=1000, \n",
    "    remove_columns=[\"category\", \"name\",'text','id'],num_proc=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e5d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.remove_columns(['brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e07f35e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 80151\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "591e8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Freeze selective layers:\n",
    "# - Freeze all layers except last n:\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "for i, m in enumerate(model.transformer.h):        \n",
    "    #Only un-freeze the last n transformer blocks\n",
    "    if i+1 > 12 - UNFREEZE_LAST_N:\n",
    "        for parameter in m.parameters():\n",
    "            parameter.requires_grad = True \n",
    "\n",
    "for parameter in model.transformer.ln_f.parameters():        \n",
    "    parameter.requires_grad = True\n",
    "\n",
    "for parameter in model.lm_head.parameters():        \n",
    "    parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c8cf457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-583dc9dc89b79cfa.arrow and /home/thienchuaheadshot_gmail_com/spin_content/data_clean/cache-13ca462ff0ca9d20.arrow\n"
     ]
    }
   ],
   "source": [
    "data_full_split = train_data.train_test_split(test_size=0.03, seed = 42)\n",
    "train_data = data_full_split[\"train\"]                                    \n",
    "test_data = data_full_split[\"test\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ed5a8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 2405\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5b68954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 01:56:00.253287: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TPURoundRobin\" device_type: \"CPU\"') for unknown op: TPURoundRobin\n",
      "2022-09-27 01:56:00.253344: E tensorflow/core/framework/op_kernel.cc:1676] OpKernel ('op: \"TpuHandleToProtoKey\" device_type: \"CPU\"') for unknown op: TpuHandleToProtoKey\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
    "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
    "    gradient_accumulation_steps=BATCH_UPDATE,\n",
    "    prediction_loss_only=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy='steps',\n",
    "    logging_steps=400,  # set to 1000 for full training\n",
    "    save_steps=1000,  # set to 500 for full training\n",
    "    eval_steps=1000,  # set to 8000 for full training\n",
    "    warmup_steps=WARMUP_STEPS,    \n",
    "    learning_rate=LR,\n",
    "    adam_epsilon=EPS,\n",
    "    weight_decay=0.01,        \n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "885bec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,    \n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e2658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 77746\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2048\n",
      "  Gradient Accumulation steps = 64\n",
      "  Total optimization steps = 148\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='148' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 19/148 20:45 < 2:37:29, 0.01 it/s, Epoch 0.47/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164e41d2",
   "metadata": {},
   "source": [
    "### Generating text with finetune GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c06edfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/vocab.json from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/7cf88785b592f4177f364d0c49db894e50b5c1c4f2a4af70dc87fe3ea5296b96.1c1d29c8ea56bae456d84e19ab8005ee46986b2f1cea420bf0ee5b6f37bc5447\n",
      "loading file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/merges.txt from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/d604f49ddd467aab72674d3a6fe91d48977020205ee65fee37edbc3793c57331.a70df4dd5bfb05f5ad6646b40581db340b74b8771c707fe89ce64b8fbf08d031\n",
      "loading file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/tokenizer.json from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/dcc1ad091eed0791d69c3b1013e546d77d35549c8c6d10316917785e2ff0cfad.61e940ecbaf4ec304b3aab441208b8185502600673c69ddc01d444307febb866\n",
      "loading file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/added_tokens.json from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/2e0c13b05c30253be7b68694dea18a31c1bd3503117627453a7cd8c09e0715a4.96c5d6ee3b47c84194a9df186239e69d3987f151b8b35ff90f003aa2a2d14f64\n",
      "loading file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/special_tokens_map.json from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/c9c91c3ccb451237f818e56b4076a7fdfcb1a4013c33ea6549bce9b37087f8e7.3ae9ae72462581d20e36bc528e9c47bb30cd671bb21add40ca0b24a0be9fac22\n",
      "loading file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/tokenizer_config.json from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/272b79710765d87e517714c86140ab1343667227222c0af3ed7d0ffdccdf4e26.124ac535cdb0e7f824591ae01c64124278c75ae3aeee7e61e8687f7a9271800c\n",
      "Assigning <|BOS|> to the bos_token key of the tokenizer\n",
      "Assigning <|EOS|> to the eos_token key of the tokenizer\n",
      "Assigning <|UNK|> to the unk_token key of the tokenizer\n",
      "Assigning <|PAD|> to the pad_token key of the tokenizer\n",
      "Assigning <|SEP|> to the sep_token key of the tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/config.json from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/797cd60ee07bb6033508bbfe7156425d229228ae730e6661005b3c85fe55dd3b.c7ce1289c7853d140ef65348be24ee2e0577490b793b1e7fcbb88e3b81737f53\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"NlpHUST/gpt2-vietnamese\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"bos_token_id\": 50258,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 50259,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50261,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"sep_token_id\": 50262,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/NlpHUST/gpt2-vietnamese/resolve/main/pytorch_model.bin from cache at /home/thienchuaheadshot_gmail_com/.cache/huggingface/transformers/5707161ef484d586632eb52af4e8b69eb19207bd5e7349a83206a98eaf998b61.7247682122ce75b7d91426ef29523457a08597d3ba244163b7f26c83816a583c\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at NlpHUST/gpt2-vietnamese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
    "model = get_model(tokenizer, \n",
    "                  special_tokens=SPECIAL_TOKENS,\n",
    "                  load_model_path='./pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc0c4cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50263, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50263, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "090eec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = \"Giày dép\"\n",
    "brand = \"Quốc Việt:\"\n",
    "name = \"Giày Quốc Việt: \"\n",
    "des = \"Sản phẩm SM05 là chiếc giày sang trọng của hãng Quốc Việt. Với thiết kế thời trang và độc đáo, bạn có thể mang theo bên mình mọi lúc trong những chuyến đi chơi xa hoặc các hoạt động vui nhộn mà không cần lo lắng về vấn đề an toàn sức khỏe khi sử dụng sản phầm này nữa nhé. Mẫu mã đẹp mắt cùng nhiều ưu điểm nổi bật khác được làm từ chất liệu da bò thật 100% đã tạo nên sự cuốn hút khó cưỡng đối với người nhìn ngay lần đầu tiên ngắm nghía mẫu giầy cao cấp chính hiệu quốc việt tại shop chúng tôi.\"\n",
    "\n",
    "prompt = SPECIAL_TOKENS['bos_token'] +cate + SPECIAL_TOKENS['sep_token'] + brand + SPECIAL_TOKENS['sep_token']+des + SPECIAL_TOKENS['sep_token'] + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86cf6f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|BOS|>Giày dép<|SEP|>Quốc Việt:<|SEP|>Sản phẩm SM05 là chiếc giày sang trọng của hãng Quốc Việt. Với thiết kế thời trang và độc đáo, bạn có thể mang theo bên mình mọi lúc trong những chuyến đi chơi xa hoặc các hoạt động vui nhộn mà không cần lo lắng về vấn đề an toàn sức khỏe khi sử dụng sản phầm này nữa nhé. Mẫu mã đẹp mắt cùng nhiều ưu điểm nổi bật khác được làm từ chất liệu da bò thật 100% đã tạo nên sự cuốn hút khó cưỡng đối với người nhìn ngay lần đầu tiên ngắm nghía mẫu giầy cao cấp chính hiệu quốc việt tại shop chúng tôi.<|SEP|>Giày Quốc Việt: '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b06396f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94c07c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 12610,  5657, 50262,  9019,   649,    30, 50262,  4147,   659,\n",
       "          8982,  3309,   314,  1076,  2664,  1218,   828,   331,  1520,   883,\n",
       "           649,    18,  1470,   695,   795,   606,   840,   309,  1295,  2039,\n",
       "            16,   430,   329,   419,   836,   608,   909,   589,   962,  1036,\n",
       "           366,   392,  2025,   585,  1092,  1353,   743,   338,   876,   535,\n",
       "          1252,  5349,   481,   359,   675,   565,  2034,   473,   889,   600,\n",
       "           841,   710,   967,  1334,   456,   603,   515,   578, 14758,   444,\n",
       "          1078,  1404,    18,  4206,  1692,   805,  1012,   648,   480,  1370,\n",
       "           738,  1179,  1838,   474,   354,   471,   450,   668,   936,   904,\n",
       "          2647,  1086,  1600,     9,   417,   707,   588,   508,  2026,  1444,\n",
       "           983,  4668,   729,   370,   390,  1103,   987,   897,   524,  1071,\n",
       "          3175, 17372,  1261,  9196,   592,   656,   577,   745,   921,  2607,\n",
       "           491,  3796,   634,   554,    18, 50262, 12610,   883,   649,    30,\n",
       "           225]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88dfa9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b8189f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-p (nucleus) text generation (10 samples):\n",
    "sample_outputs = model.generate(generated,do_sample=True, min_length=20, max_length=300,top_k=30,top_p=0.7,temperature=0.9,repetition_penalty=2.0,num_return_sequences=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "396f0078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Giày dépQuốc Việt:Sản phẩm SM05 là chiếc giày sang trọng của hãng Quốc Việt. Với thiết kế thời trang và độc đáo, bạn có thể mang theo bên mình mọi lúc trong những chuyến đi chơi xa hoặc các hoạt động vui nhộn mà không cần lo lắng về vấn đề an toàn sức khỏe khi sử dụng sản phầm này nữa nhé. Mẫu mã đẹp mắt cùng nhiều ưu điểm nổi bật khác được làm từ chất liệu da bò thật 100% đã tạo nên sự cuốn hút khó cưỡng đối với người nhìn ngay lần đầu tiên ngắm nghía mẫu giầy cao cấp chính hiệu quốc việt tại shop chúng tôi.Giày Quốc Việt: \n",
      "+ Đế bằng nhựa tổng hợp siêu bền chống trơn trượt tốt, giúp cho việc di chuyển trên đôi chân trở lên dễ dàng hơn bao giờ hết.Giày QuốcViệt: đẹpCÂU HỎI TRẮC NGHIỆM Trắc nghiệm Vật lý lớp 10 Bài 1: Câu hỏi trắc nghiệm vật lí 12 câu A - B Biên soạn bởi thầy giáo Lê Hồng Minh Đề thi học kì I môn Hóa Học THPT năm 2018 trường thpt chuyên Bắc Ninh đáp án chi tiết dưới đây mời quý vị xem Đáp Án Chi Tiết Môn Lý Lớp 11 Mời quý phụ huynh chú ý! 1) Cho biết phản ứng hóa học xảy ra như thế nào? 2 ) Phản Ứng Hoá Chất Của Hợp Kim Nhôm (Cu)? 3). 4) Viết phương trình hoá học của\n",
      "\n",
      "\n",
      "2: Giày dépQuốc Việt:Sản phẩm SM05 là chiếc giày sang trọng của hãng Quốc Việt. Với thiết kế thời trang và độc đáo, bạn có thể mang theo bên mình mọi lúc trong những chuyến đi chơi xa hoặc các hoạt động vui nhộn mà không cần lo lắng về vấn đề an toàn sức khỏe khi sử dụng sản phầm này nữa nhé. Mẫu mã đẹp mắt cùng nhiều ưu điểm nổi bật khác được làm từ chất liệu da bò thật 100% đã tạo nên sự cuốn hút khó cưỡng đối với người nhìn ngay lần đầu tiên ngắm nghía mẫu giầy cao cấp chính hiệu quốc việt tại shop chúng tôi.Giày Quốc Việt: &aacu...\n",
      "Mẫu Giày Nam Cao Cấp Chính Hãng MS014-3 là dòng giay nam dep co gai gia rẻ nhất trên thị trường hiện nay, Sản Phẩm chỉ dành cho quý ông lịch lãm và mạnh mẽ, giúp phái mạnh tự tin hơn bao giờ hết mỗi bước chân.Với kiểu dáng thanh mảnh, gọn nhẹ vừa vặn ôm trọn bàn tay chắc chắn sẽ khiến chàng cảm thấy thoải mái tuyệt vời. Đế TF êm ái tăng cường độ bám mặt đất chống trơn trượt, chống thấm nước tối đa. đế còn chịu lực ma sát tốt, đàn hồi cực kỳ bền bỉ. cạnh tranh chấp ở xung quanh. với khả năng phát huy tác hại của tia bức xạ hồng ngoại, đèn led Philips S398 còn góp phần bảo vệ con trẻ khỏi\n",
      "\n",
      "\n",
      "3: Giày dépQuốc Việt:Sản phẩm SM05 là chiếc giày sang trọng của hãng Quốc Việt. Với thiết kế thời trang và độc đáo, bạn có thể mang theo bên mình mọi lúc trong những chuyến đi chơi xa hoặc các hoạt động vui nhộn mà không cần lo lắng về vấn đề an toàn sức khỏe khi sử dụng sản phầm này nữa nhé. Mẫu mã đẹp mắt cùng nhiều ưu điểm nổi bật khác được làm từ chất liệu da bò thật 100% đã tạo nên sự cuốn hút khó cưỡng đối với người nhìn ngay lần đầu tiên ngắm nghía mẫu giầy cao cấp chính hiệu quốc việt tại shop chúng tôi.Giày Quốc Việt: \n",
      "1) Sản Phẩm Giày Thể Thao Nữ Đế Bằng YCN0011-T3B (Đen Xanh Lá - Size M/L ) : - đế bằng nhựa ABS chịu lực tốt, chống trơn trượt và dễ dàng di chuyển trên đôi chân. 2) Lót dưới đệm mút êm ái giúp nâng đỡ bàn đạp tối đa đồng thơi giảm chấn thương cho gót và hông. 3) Chất vải mềm mại thoáng khí thấm mồ hôi rất phù hợp để tập luyện hay vận hành ở cường độ mạnh như chạy bộ, leo núi... 4) Màu sắc trẻ trung thanh lịch dễ phối đồ và mix&match cũng khá bắt sáng với áo phông kẻ ngang tay dài + quần jeans suông ống rộng vừa vặn cơ bụng 5) Lớp lót xốp mịn, nhẹ nhàng, lớp bọt biển dày ngăn nước mưa thoát ra ngoài, giữ ấm vào mùa đông\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    text = tokenizer.decode(sample_output, skip_special_tokens=True)   \n",
    "    print(\"{}: {}\\n\\n\".format(i+1, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836fef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
